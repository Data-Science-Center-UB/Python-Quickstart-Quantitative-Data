{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48eca60f-5bb9-49b3-aebd-30cffd9d99cb",
   "metadata": {},
   "source": [
    "<img src=\"../Images/DSC_Logo.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f387c-9f50-4373-9f5a-b2ef0a1c2089",
   "metadata": {},
   "source": [
    "# Fundamental Python Libraries for Data Handling\n",
    "\n",
    "This notebook introduces how to import data from external files, write data back to files, and use the most commonly used Python libraries for working with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f20a8e6-72eb-42f9-a609-facdbea9bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install xarray\n",
    "!pip install py7zr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f820b-49b6-4330-a27a-67fd81f4fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import py7zr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7475f-703b-4fde-8045-b43e5eefbd13",
   "metadata": {},
   "source": [
    "## 1. Reading and Writing Text Files\n",
    "\n",
    "Up until now, we’ve worked only with data created inside our own code. But in real-world projects, you’ll mainly work with existing data and files. Let's see how to open and read text files, as well as how to save (write) new files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808e94b-2c5d-4366-be4e-5a2d687d6203",
   "metadata": {},
   "source": [
    "We can use the `with` statement togeter with `f.write()` **to save a text file**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd06d0fd-6139-4489-8a64-7175af276916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_string = \"These are my notes on experiment A.\"\n",
    "\n",
    "# Save as text file (to a relative path) in write mode (\"w\"):\n",
    "with open(\"../Data/Notes.txt\", \"w\") as f:\n",
    "    f.write(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a493bdbb-cd8e-4ff6-a175-0030bddfae9c",
   "metadata": {},
   "source": [
    "**To import a text file**, we use almost the same structure, but change the mode to \"r\" (read):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a77a0-1ae0-435d-99af-403b191d19dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open the file \"World-happiness-report-2024.csv\" (from a relative path) in read mode (\"r\"):\n",
    "with open(\"../Data/Iris.csv\", \"r\") as f: \n",
    "    data = f.read()\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b035f66-f0b4-4386-8b60-f566d2ca909a",
   "metadata": {},
   "source": [
    "This reads the contents of .csv file and stores it in the variable \"data\". You notice, however, that this file import does **not account for the comma-separation**.\n",
    "\n",
    "If you want to read the file in a **structured** way using the comma (\",\") as a separator, then instead of using `f.read()`, you should use the `csv` module or the `pandas` library. These tools understand the structure of CSV files and will split the data into rows and columns for you.\n",
    "\n",
    "*Note: Terms like module, package, and library are often used interchangeably in Python. While they all refer to reusable Python software, there are subtle differences in structure and scale. A module is the simplest unit, just a single .py file containing Python code. When several modules are grouped together in a folder, this is known as a package. A library, on the other hand, is a more general term. It typically refers to a collection of related packages and modules that together provide tools for a specific purpose.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54541fe1-2555-4665-a907-8cc84f1e2877",
   "metadata": {},
   "source": [
    "## 2. Automatically Loading Multiple Text Files with `glob`\n",
    "\n",
    "This is handy for batch processing or analyzing many files at once without manually opening each one. You can also combine `glob` with `os` or `pathlib` to interact with the operating system (e.g., navigating folders, creating/deleting files).\n",
    "\n",
    "Suppose you have a folder with multiple .txt files. You want to **automatically load all these files** to analyze them in Python. The `glob` library allows you to search for files in a folder based on patterns. In this example, we’ll load all .txt files from a folder and print their contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8136a8-ef5d-459b-9339-566da5eb153d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the glob library (part of Python’s standard library)\n",
    "import glob\n",
    "\n",
    "# Get all text files in the \"Samples\" folder\n",
    "files = glob.glob(\"../Data/Samples/*.txt\")\n",
    "\n",
    "# Read and display contents of each file\n",
    "for filepath in files:\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4332fa5-6e12-46f9-8844-d0b4e1f0f11b",
   "metadata": {},
   "source": [
    "## 3 Using `pandas` for Tabular Data\n",
    "\n",
    "`pandas` is the most widely used Python library for working with **tabular data** (data arranged in rows and columns) commonly found in files like .csv or Excel spreadsheets. `pandas` reads such files into **dataframes**, which keep both the data and its structure intact. This allows you to efficiently explore, organize, and analyze data within your code. \n",
    "\n",
    "**Dataframes** are similar to Excel spreadsheets or database tables. They have a **2-dimensional** data structure and **labeled axes (rows and columns)**. These are **indexed** for efficient data retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26e147-3254-4530-8dd1-9458c9ba8fb3",
   "metadata": {},
   "source": [
    "<img src=\"../Images/dataframe.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6780a43a-9f07-42d9-a08c-bff1140bc3ec",
   "metadata": {},
   "source": [
    "Let's use `pandas` for **importing** the text file from Sect. 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32757b1-ad00-4982-a61d-089dedb78012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Iris = pd.read_csv(\"../Data/Iris.csv\")\n",
    "print(Iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c73ffc-1eed-46d4-ae73-0f4d69a8ef94",
   "metadata": {},
   "source": [
    "To **create a DataFrame** from a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3300775-26e4-4ada-b94c-0081cdf17c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_dict = {\"names\": [\"Alice\", \"Mary\", \"Kim\", \"Deniz\", \"Carla\", \"Linus\"]}\n",
    "df = pd.DataFrame(names_dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98173cdc-54ba-44ff-bec9-e614d995fe6f",
   "metadata": {},
   "source": [
    "**Saving** a DataFrame to CSV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aaec591-eb47-4adc-b81d-6b81fa6d7bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee62ccc-9d81-4341-8797-6e722bd8b60f",
   "metadata": {},
   "source": [
    "Setting `index=False` prevents pandas from writing row indices to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc17a27-24a8-4d1b-b4e9-63a787770dbe",
   "metadata": {},
   "source": [
    "## 4. Using `numpy` for Fast Numerical Computing\n",
    "\n",
    "`numpy` is **the foundational library for numerical computing**, supporting large and multi-dimensional **arrays** and vectorized operations. A data array is a structure for stroring elements of the same type. Arrays can be one-dimensional or multi-dimensional (like a matrix).\n",
    "\n",
    "Actually, many Python libraries are build on top of `numpy`, including `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00a2d7-068e-45e9-9ea8-e08ed872e8e4",
   "metadata": {},
   "source": [
    "<img src=\"../Images/array.png\" style=\"width: 600px;\"> <img src=\"../Images/pandas_numpy.png\" style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18238825-10eb-4ea5-b9f1-718e9450c6c0",
   "metadata": {},
   "source": [
    "Let's **import** some data (temperature anomaly time series) as a 2D NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db2a21-51cb-45d3-8183-fe8b3a249bf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series = np.loadtxt('../Data/NOAA_time_series.csv', skiprows=5, delimiter=',')\n",
    "print(time_series[:5]) # index the array to prints the first 5 \"rows\" (along axis 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d691530-d6f3-414c-aa68-fdd5021614dd",
   "metadata": {},
   "source": [
    "To **create** a 2D NumPy array from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1c0dcf-1515-4f45-b851-1d78962bb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df835e52-f21a-43d9-846e-9660b52a1be3",
   "metadata": {},
   "source": [
    "NumPy can also handle **multi-dimensional data**, such as 3D arrays, which are useful for representing things like image stacks or time-varying data. Here's a basic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563746a0-13a0-4d25-b723-49d8deed0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D array: 2 \"layers\", each 3x3\n",
    "data = np.array([\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]],\n",
    "\n",
    "    [[10, 11, 12],\n",
    "     [13, 14, 15],\n",
    "     [16, 17, 18]]\n",
    "])\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b7eef-7cfb-41b4-ba60-2414870abf98",
   "metadata": {},
   "source": [
    "### Converting Between NumPy Arrays and pandas DataFrames\n",
    "\n",
    "NumPy arrays are great for fast numerical operations. However, they lack labels (like column names), which makes DataFrames more convenient for data exploration and analysis.\n",
    "\n",
    "Here is how you can **convert** between the two data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d0d1a2-3e52-4937-a43f-19c8afc0d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to pandas DataFrame\n",
    "df = pd.DataFrame(time_series, columns=['Year', 'Anomaly'])\n",
    "print(df.head()) # .head prints the first 5 rows of the df by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c317ef1a-8af7-4454-88c7-e96872ce8e22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert DataFrame back to NumPy array\n",
    "array_again = df.values\n",
    "print(array_again[:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0744958a-34ef-492a-abb0-8e7236e8622f",
   "metadata": {},
   "source": [
    "## 5. Complex File Structures: `xarray` for netCDF Files\n",
    "\n",
    "`xarray` is **like `pandas` for netCDF**, it is a powerful library for handling and analyzing multi-dimensional arrays, commonly used for time series data in the Earth sciences.\n",
    "\n",
    "Let's see how 3D climate data can be easily imported using `xarray`. The dataset contains two variables (t2m and tp) each have three dimensions: (time, latitude, longitude)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de68891-d6bb-4525-945f-b49604c803c8",
   "metadata": {},
   "source": [
    "If not unpacked already, the .7z file must be unpacked (use py7zr library):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5480497-d06b-4db8-89eb-6d4a8c34bedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with py7zr.SevenZipFile('../Data/ERA5_snippet.7z', mode='r', password='secret') as archive:\n",
    "    archive.extractall(path='../Data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d108600-1233-49a3-ab6c-33b48c3311e2",
   "metadata": {},
   "source": [
    "Import file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9609735a-d1e6-4b97-a9ee-c1934aef46f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERA5 = xr.open_dataset('../Data/ERA5_snippet.nc')\n",
    "print(ERA5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2442556d-867e-4b88-a612-044908615419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
